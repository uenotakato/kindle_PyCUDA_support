# 1. はじめに
- CUDA（Compute Unified Device Architecture；日本語でコンピュート統一デバイスアーキテクチャ）
- pyCUDAは，C言語をGPU並列計算用に拡張したCUDAのCのラッパーライブラリ
  - CUDACと比べメモリの管理を極めて簡単にできる
- 本書に向いている人
  - Pythonのプログラミング経験があり，自分でGPU並列のコードを書きたい方
    - memo）書きたい
  - 今までCPU並列計算をしてきたが，GPUでの並列計算方法を知りたい方
    - memo）この経験ないけど知りたい
- GPGPU（General Purpose GPU）は，GPUの利用用途を画像処理以外に拡張させたもの
- コア数が大きく異なり，このコア数の数が計算速度をになっている
![](/images/2023-05-03-17-22-08.png)
- 演算性能はFloating point number Operation Per Second（FLOPS）と呼ばれる単精度浮動小数点演算性能で評価される
  - FLOPSは一秒間に浮動小数演算が何回行えるかという計算能力を意味する
  - 1FLOPS＝1秒間に1回の浮動小数点演算
- TFLOPSのT（テラ）は$10^12$を意味する。
  - TFLOPS=1秒間に1兆回の浮動小数点演算
- GPGPUを取り扱うプログラミング言語は，CUDA，OpenCL，OpenACCの三つがある
  - CUDAとOpenCLはC言語がベース
  - CUDAはこの三つの中で最も高速
  - OpenACCはCUDAやOpenCLのような書き直す手間をなるべく抑えるために開発された比較的新しい言語
    - 手軽にGPU並列を始めたい人向け
      - memo）セミナーで紹介されていたのが確かOpenACCだった気がする
# 2. 環境構築：ハード編
- マザーボードの外観
![](/images/2023-05-03-17-37-05.png)
- 本書はGPU1基を用いたSingle-GPUでの計算
- GPUを選ぶ際に見るべきポイントを学習する
  - NVIDIA GeForceRTX2080Tiを例にする
![](/images/2023-05-03-17-39-06.png)
- CUDAコア：GPU内部で四則演算を行うための演算部分
  - CUDAコアが4352ということは，4352並列が可能ということ
  - CUDAコアはFLOPSに大きく影響する
    - 実用上8FLOPSあれば，CsPUと比較して計算速度の速さを実感できる
- メモリ構成はGPUで利用できるメモリ容量
  - GPU並列では通常計算をGPU上で行うことになるため，変数はGPU上のメモリに格納されることになる
  - GPU並列で計算できる計算規模の上限はGPUメモリ容量が決めている
    - そのためメモリ構成もFLOPSに大きく影響する
- NVLinkは最近のGPUに搭載されている機能
  - CPUとGPUを直接ブリッジして繋ぐ機能がNVLinkで，GPU間のデータのやり取りがかなり高速化される
# 3. 環境構築：ソフト編
# 4. CUDAの基礎知識
- CUDAでの計算を行う場合の一般的な計算の流れ
  - 計算が始まるとまずGPU上で計算を行うためにCPUのメモリをGPUに転送する
  - 次にCUDAカーネルと呼ばれるGPU並列の計算部分をGPU上で実行する
  - 最後に，CPUからGPUへ計算結果を転送する
![](/images/2023-05-03-17-49-24.png)
- CUDAカーネルが大事
- CUDAカーネルとは，GPUで計算を行う場合のメインとなる関数部分
  - 通常数値計算ではforループを使うことが多い
  - この部分の演算をCUDAカーネルで計算することになる
- pyCUDAはCUDA Cのラッパーライブラリ
  - そのため，CUDA Cでカーネルの内容をプログラミングすることになる
- CUDAカーネルを実行すると，多くのCUDAコアが同時にカーネルを実行することになる
- このとき，計算を行う最小単位はスレッド（thread）と呼ばれる単位
  - そのスレッドを一定の数束ねた単位がブロック（block）と呼ばれる単位
  - さらにそのブロックを束ねた単位がグリッド（grid）と呼ばれるもの
![](/images/2023-05-06-12-45-58.png)
- ブロックやスレッドの分割方法は様々
  - 一次元から三次元まで
- CUDAでの計算時，1つのグリッドに含まれるブロック数やブロックに含まれるスレッド数は自身で決定しなければならない
- スレッド数とブロック数の指定をして，カーネルを実行すると，各スレッドが計算を始める。
- この計算ではワープ（Warp）と呼ばれる32個のスレッド単位で計算を行う
- Warpは32個ある
![](/images/2023-05-06-12-52-43.png)
- このため，1ブロックあたりのスレッド数は32の倍数が望ましく，一次元のブロックであればthreads_per_block=(256, 1, 1)や(512, 1, 1), 二次元であれば（16, 16, 1）などを用いることが多い（全て32の倍数）
- 一つのWarp内にある32個のスレッドは全て同じ命令を実行するが，このような並列化の命令をSIMT（Single Instruction Multiple Thread）と呼ぶ。
- 同一Warp内の32個のスレッドは全て同じ命令を実行する。
  - このため，CUDAカーネル内にif文による分岐がいくつもあり，スレッド毎に別々の条件が当てはまるような場合，それら条件式を全てのスレッドが実行するようになり，計算速度の低下が起こる
  - この現象をWarpダイバージェンスと呼び，CUDAプログラミングで計算速度を出すには避ける必要がある
- むやみやたらにif文を使うと，Warpダイバージェンスが起きる
- GPUはCPUと独立した独自のメモリに変数・配列を保存して計算を実行する。
- このため，CUDAでプログラミングを行う場合，GPUのメモリを意識してプログラムを書く必要がある。
![](/images/2023-05-06-12-57-42.png)
- GPUのメモリは大まかにオンチップメモリとオフチップメモリの二つに分かれる
- オンチップメモリはStreaming Multiprocessor（SM）と呼ばれる演算装置の中にメモリが実装されており，実際に演算を行うCUDA Coreと距離が近いため，メモリへのアクセスが速いという特徴がある
- その代わり，記憶容量が小さいため，あまり多くの変数を格納することができない
- オンチップメモリとしては以下の三つがある
  - sharedメモリ
  - L1キャッシュ
  - レジスタ
- 通常，CUDAカーネル内で変数を宣言し，値を格納するとレジスタに格納されるがレジスタに収まりきらないものはローカルメモリに保存される。
- オフチップメモリはオンチップメモリと反対の性質を持っている。
- つまり，大容量であるがメモリへのアクセスが遅い
- オフチップメモリとしては，以下の5つがある
  - L2キャッシュ
  - コンスタントメモリ
  - テクスチャメモリ
  - グローバルメモリ
  - ローカルメモリ
- CUDAカーネルの実行時に引数として与えた変数は通常，グローバルメモリに保存される
  - テクスチャメモリは少し特殊なオフチップメモリ。オフチップメモリにも関わらず，メモリへのアクセスが速く，メモリも大容量である。
- その代わり，GPU上では読み取り専用のメモリで，GPU上で書き換えをすることができない。
- テクスチャメモリは計算途中で変化しない変数などに利用することが考えられる
# 5. PyCUDAの基礎(1):CUDAの基本
## 5-1. 最低限必要なC言語
- `C_source`を参照しながら読み進めた
## 5-2. Hello World
- PyCUDA版のHello Worldプログラムとして，GPU上での四則演算を取り扱う。
  - `hello_cuda.py`を参照した
  - 10個の要素を持ったnumpy配列をGPUに送って全ての要素に1を足しCPUにもどす
## 5-3. 一次元配列の四則演算
- ElementwiseKernelは簡単なCUDAカーネルであれば問題ないが少し処理が長い場合や複雑なカーネルだと対応が難しくなる
- そこで，CUDA Cのカーネルコードを直接扱うSourceModuleを利用する
- `1d_array_calc.py`を参照
  - CUDAカーネルの中の`__global__`，`__device__`設定の違いについて
    - `__global__`: GPU上からでもCPU上からでも呼び出すことができる関数，GPU上からCPU上へと返すことができないため戻り値はvoidとなる。
    - `__device__`: GPU上からのみ呼び出すことができる関数，GPU上のみで動作するため戻り値はvoid（何も返さない）以外を設定することも可能
  - 通常は`__global__`を使うことが多い
    - `__device__`は`__global__`で書いたときに煩雑になりそうな際に使う
- ![](/images/2023-05-19-18-53-37.png)
## 5-5. CPU vs GPU
- メモリコピーがGPUの実行時間のうち99.9%を占めるのが原因で，GPUとCPUの時間差がほとんど存在しない
- GPU上で並列計算したいのであれば，使う配列を全てGPU上のメモリにコピーして，基本的にはGPU上で値を更新し続けて，ファイル出力など必要なときだけGPUからCPUへメモリコピーを行う
